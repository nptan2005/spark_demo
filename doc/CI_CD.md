# ‚úÖ M·ª§C TI√äU
````code
git push ‚Üí GitHub Actions ‚Üí Auth OIDC ‚Üí Upload DAG ‚Üí Composer DAG folder ‚Üí Airflow load DAG ‚Üí (optional) Trigger DAG
````

# B∆Ø·ªöC 0 ‚Äî CHU·∫®N HO√Å TH√îNG TIN:

## Th√¥ng tin

```text
PROJECT_ID = my-cdp-demo-01
REGION = asia-southeast1
COMPOSER_ENV = airflow-test-01
REPO = nptan2005/spark_demo
SERVICE ACCOUNT CI = ci-deployer@my-cdp-demo-01.iam.gserviceaccount.com
WORKLOAD_IDENTITY_POOL = github-pool
WORKLOAD_IDENTITY_PROVIDER = github-provider
```

# B∆Ø·ªöC 1 ‚Äî T·∫†O SERVICE ACCOUNT CHO CI/CD:

Ch·∫°y tr√™n **Cloud Shell**:

```bash
PROJECT_ID="my-cdp-demo-01"
SA_NAME="ci-deployer"
SA_EMAIL="${SA_NAME}@${PROJECT_ID}.iam.gserviceaccount.com"

gcloud iam service-accounts create "${SA_NAME}" \
  --display-name="GitHub CI deploy DAGs to Composer"
```

# B∆Ø·ªöC 2 ‚Äî G√ÅN QUY·ªÄN CHO SERVICE ACCOUNT

## 2.1 ‚Äî Cho ph√©p CI upload DAG v√†o bucket Composer:

```bash
gcloud projects add-iam-policy-binding my-cdp-demo-01 \
  --member="serviceAccount:${SA_EMAIL}" \
  --role="roles/storage.objectAdmin"
```

## 2.2 ‚Äî Cho ph√©p CI trigger DAG:

```bash
gcloud projects add-iam-policy-binding my-cdp-demo-01 \
  --member="serviceAccount:${SA_EMAIL}" \
  --role="roles/composer.admin"
```

## 2.3 ‚Äî Cho ph√©p CI impersonate qua OIDC:

S·∫Ω th·ª±c hi·ªán ·ªü b∆∞·ªõc 4.

# B∆Ø·ªöC 3 ‚Äî T·∫†O WORKLOAD IDENTITY POOL & OIDC PROVIDER:

```bash
POOL_ID="github-pool"
PROVIDER_ID="github-provider"

gcloud iam workload-identity-pools create "${POOL_ID}" \
  --location="global" \
  --display-name="GitHub Actions Pool"


gcloud iam workload-identity-pools providers create-oidc "${PROVIDER_ID}" \
  --location="global" \
  --workload-identity-pool="${POOL_ID}" \
  --display-name="GitHub Provider" \
  --issuer-uri="https://token.actions.githubusercontent.com" \
  --attribute-mapping="google.subject=assertion.sub,attribute.repository=assertion.repository,attribute.actor=assertion.actor" \
  --attribute-condition="assertion.repository=='nptan2005/spark_demo'"
```

# B∆Ø·ªöC 4 ‚Äî CHO GITHUB REPO ƒê∆Ø·ª¢C IMPERSONATE SERVICE ACCOUNT:

B·∫°n d√πng repo:
üëâ nptan2005/spark_demo

```bash
PROJECT_NUMBER=$(gcloud projects describe my-cdp-demo-01 --format="value(projectNumber)")
POOL_ID="github-pool"

gcloud iam service-accounts add-iam-policy-binding \
  ci-deployer@my-cdp-demo-01.iam.gserviceaccount.com \
  --project="my-cdp-demo-01" \
  --role="roles/iam.workloadIdentityUser" \
  --member="principalSet://iam.googleapis.com/projects/${PROJECT_NUMBER}/locations/global/workloadIdentityPools/${POOL_ID}/attribute.repository/nptan2005/spark_demo"
```

# B∆Ø·ªöC 5 ‚Äî T·∫†O GI√Å TR·ªä SECRET CHO GITHUB REPO:

V√†o:
```
GitHub ‚Üí spark_demo ‚Üí Settings ‚Üí Secrets and Variables ‚Üí Actions ‚Üí New Repository Secret
```

| **Key**                  |   **Values**                                                                   |
|--------------------------|--------------------------------------------------------------------------------|
|GCP_PROJECT|my-cdp-demo-01|
|GCP_SA_EMAIL|ci-deployer@my-cdp-demo-01.iam.gserviceaccount.com|
|WIF_POOL_ID|github-pool|
|WIF_PROVIDER_ID|github-provider|
|COMPOSER_ENV|airflow-test-01|
|COMPOSER_REGION|asia-southeast1|

# B∆Ø·ªöC 6 ‚Äî T·∫†O FILE WORKFLOW CI/CD:

Trong repo spark_demo, t·∫°o file:

```
.github/workflows/deploy_dags.yml
```
## V·ªõi n·ªôi dung FULL & CHU·∫®N NH·∫§T:


```yaml
name: Deploy DAGs to Composer

on:
  push:
    branches: [ "main" ]
    paths:
      - "dags/**"

permissions:
  id-token: write
  contents: read

env:
  PROJECT_ID: ${{ secrets.GCP_PROJECT }}
  COMPOSER_ENV: ${{ secrets.COMPOSER_ENV }}
  COMPOSER_REGION: ${{ secrets.COMPOSER_REGION }}
  DAGS_DIR: "dags"

jobs:
  deploy:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Authenticate to Google Cloud via OIDC
        uses: google-github-actions/auth@v2
        with:
          workload_identity_provider: "projects/${{ env.PROJECT_ID }}/locations/global/workloadIdentityPools/${{ secrets.WIF_POOL_ID }}/providers/${{ secrets.WIF_PROVIDER_ID }}"
          service_account: ${{ secrets.GCP_SA_EMAIL }}

      - name: Setup gcloud CLI
        uses: google-github-actions/setup-gcloud@v2
        with:
          project_id: ${{ env.PROJECT_ID }}
          export_default_credentials: true

      - name: Get Composer DAGS bucket
        id: dag_bucket
        run: |
          BUCKET=$(gcloud composer environments describe "${{ env.COMPOSER_ENV }}" \
            --location "${{ env.COMPOSER_REGION }}" \
            --format="value(config.dagGcsPrefix)")
          echo "bucket=$BUCKET" >> $GITHUB_OUTPUT

      - name: Sync DAGs to Composer
        run: |
          echo "Deploying DAG files..."
          gsutil -m rsync -r "./${{ env.DAGS_DIR }}" "${{ steps.dag_bucket.outputs.bucket }}"

      - name: Trigger DAG (optional)
        if: ${{ github.ref == 'refs/heads/main' }}
        run: |
          echo "Triggering DAG: spark_test_dag (change name if needed)"
          gcloud composer environments run "${{ env.COMPOSER_ENV }}" \
            --location "${{ env.COMPOSER_REGION }}" \
            dags trigger -- spark_test_dag || true
```

# üëå TEST:

## 1Ô∏è‚É£ T·∫°o th∆∞ m·ª•c dags/ trong repo:

```code
spark_demo/dags/spark_test_dag.py
```
spark_test_dag.py:

```python
from datetime import datetime
from airflow import DAG
from airflow.providers.google.cloud.operators.dataproc import DataprocSubmitJobOperator

PROJECT_ID = "my-cdp-demo-01"
REGION = "asia-southeast1"
CLUSTER_NAME = "my-cluster"

PYSPARK_URI = "gs://my-cdp-bronze/jobs/sample_job.py"

JOB = {
    "reference": {"project_id": PROJECT_ID},
    "placement": {"cluster_name": CLUSTER_NAME},
    "pyspark_job": {"main_python_file_uri": PYSPARK_URI},
}

with DAG(
    dag_id="spark_test_dag",
    schedule_interval=None,
    start_date=datetime(2024, 1, 1),
    catchup=False,
) as dag:

    run_spark = DataprocSubmitJobOperator(
        task_id="run_spark",
        job=JOB,
        region=REGION,
        project_id=PROJECT_ID,
    )
```

## 2Ô∏è‚É£ Commit + Push:

```bash
git add .
git commit -m "add spark dag"
git push origin main
```

‚Üí GitHub Actions ch·∫°y
‚Üí T·ª± ƒë·ªông upload DAG
‚Üí Airflow load DAG
‚Üí N·∫øu b·∫°n b·∫≠t trigger th√¨ DAG ch·∫°y lu√¥n.


